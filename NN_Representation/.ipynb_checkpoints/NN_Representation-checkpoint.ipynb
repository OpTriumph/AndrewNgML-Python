{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('ex3data1.mat')\n",
    "data1 = pd.DataFrame(np.hstack((mat['X'], mat['y'])))\n",
    "\n",
    "X = data1.iloc[:,:400]\n",
    "y = data1[[400]]\n",
    "# y.loc[:500] = 0.0\n",
    "input_layer_size = 400\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random digit chosen from the dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "rand_example = np.random.choice(X.index)\n",
    "_, ax = plt.subplots()\n",
    "   \n",
    "digit = X.iloc[rand_example].values.reshape(20, 20)\n",
    "rotated = ndimage.rotate(digit, 90)\n",
    "ax.matshow(rotated, origin = 'lower')\n",
    "print(\"random digit chosen from the dataset\")\n",
    "ax.set_title(\"Label: %i\\n\" % y.loc[rand_example])\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g = 1/ (1 + np.exp(-z))\n",
    "    return g\n",
    "\n",
    "def hypothesis( X,theta):\n",
    "    \n",
    "    return sigmoid(np.dot(X,theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize Cost Function\n",
    "\n",
    "def lrCostFunction(theta, X, y, lambd):\n",
    "    m = len(y)\n",
    "    J = 0\n",
    "    \n",
    "    J =  1/m *(np.dot(-y.T, np.log(hypothesis(X,theta))) - (np.dot((1-y).T ,  np.log(1-hypothesis(X,theta)))))+ lambd * np.dot(theta[1:].T, theta[1:]) / (2* m)\n",
    "   \n",
    "    return J.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,theta,y,lambd):\n",
    "    m = len(y)\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    grad[0] = 1/m * np.dot(X[:,0].T,(hypothesis(X,theta) - y))\n",
    "    grad[1:] =  1/m * np.dot(X[:,1:].T,(hypothesis(X,theta) - y))+ lambd * theta[1:] / m\n",
    "    while grad[1:].all() != 0:\n",
    "            grad[1:] =  1/m * np.dot(X[:,1:].T,(hypothesis(X,theta) - y))+ lambd * theta[1:] / m\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_t = np.array([-2, -1, 1, 2],ndmin = 2).T\n",
    "\n",
    "\n",
    "X_t = np.ones((5,1))\n",
    "X_t = np.c_[X_t, np.array([[0.1, 0.6, 1.1], [0.2, 0.7, 1.2], [0.3, 0.8, 1.3], [0.4, 0.9, 1.4], [0.5, 1.0, 1.5]])]\n",
    "\n",
    "y_t = np.array([1, 0, 1,0 ,1],ndmin = 2).T\n",
    "lambd_t= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected cost: 2.534819;    calculated cost: 2.534819 <class 'numpy.ndarray'>\n",
      "expected gradients:\n",
      " 0.146561\n",
      " -0.548558\n",
      " 0.724722\n",
      " 1.398003\n",
      "\n",
      "calculated gradients: \n",
      " [[ 0.14656137]\n",
      " [-0.54855841]\n",
      " [ 0.72472227]\n",
      " [ 1.39800296]]\n"
     ]
    }
   ],
   "source": [
    "cost = lrCostFunction(theta_t, X_t, y_t,lambd_t)\n",
    "gradient = gradientDescent(X_t,theta_t,y_t,lambd_t)\n",
    "print(\"expected cost: 2.534819;    calculated cost: %0.6f\"% cost, type(gradient))\n",
    "print(\"expected gradients:\\n 0.146561\\n -0.548558\\n 0.724722\\n 1.398003\\n\")\n",
    "print(\"calculated gradients: \\n\", gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-vs- All training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradOptimization(X,theta,y,lambd,alpha,num_iters):\n",
    "    m = len(y)\n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        cost = lrCostFunction(theta,X,y,lambd)\n",
    "        grad = gradientDescent(X,theta,y,lambd)\n",
    "        theta = theta - alpha * grad\n",
    "        J_history.append(cost)\n",
    "        \n",
    "    return theta, J_history\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X,y,num_labels,lambd):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    all_theta =[]\n",
    "    initial_theta = np.zeros((X.shape[1] + 1, 1))\n",
    "\n",
    "    X = np.c_[  np.ones((m,1))+1 , X ]\n",
    "    \n",
    "#     optimization using Gradient Descent method\n",
    "    for i in range(1,num_labels + 1):\n",
    "        theta, J_hist = GradOptimization(X,initial_theta,np.where(y==i,1,0),lambd,3,500)\n",
    "        all_theta.extend(theta)\n",
    "        \n",
    "    return np.array(all_theta).reshape(num_labels,n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the optimized Theta\n",
    "\n",
    "theta = oneVsAll(X,y,num_labels,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Vs-All Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(theta, X):\n",
    "    m = X.shape[0]\n",
    "    X = np.c_[np.ones((m,1)) , X ]\n",
    "    predictions = (X @ theta.T)\n",
    "    return np.argmax(predictions,axis = 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Vs All classifier for MNIST accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.38"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"One Vs All classifier for MNIST accuracy:\")\n",
    "np.mean((prediction(theta, X) == y.values.flatten())*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
